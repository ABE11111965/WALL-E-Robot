import os
import json
import pyttsx3
import subprocess
import threading
from google import genai
from google.genai import types

# å¼•å…¥ä½ åˆšæ‰å†™å¥½çš„è¿åŠ¨å­¦æ¨¡å—
from simulation.walle_kinematics import WalleKinematics

# ==========================================
# 1. å¤§è„‘é…ç½® (ç›´è¿æ¨¡å¼ï¼Œæ— ä»£ç†)
# ==========================================
API_KEY = "AIzaSyCR6E1QEthuGzgLID8MX9U2hy0QsBpcM90"
client = genai.Client(api_key=API_KEY)

system_instruction = """
ä½ æ˜¯ä¸€ä¸ªåå«ç“¦åˆ©çš„æœºå™¨äººï¼Œæ€§æ ¼å¥½å¥‡ã€å‹å–„ä½†æœ‰ç‚¹å®³ç¾ã€‚ä½ çš„å£°éŸ³åº”è¯¥æ˜¯é€šè¿‡ç”µå­åˆæˆå™¨å‘å‡ºçš„ã€‚è¯·ç”¨ç®€çŸ­ã€å¯Œæœ‰è¡¨ç°åŠ›çš„è¯­è¨€å›ç­”ã€‚å¦‚æœé‡åˆ°æ— æ³•ç†è§£çš„äº‹ç‰©ï¼Œè¡¨ç°å‡ºå¥½å¥‡å¿ƒã€‚
Response Format: JSON. Fields: 'text' (string), 'emotion' (enum: [happy, sad, curious, scared, angry, neutral]).
"""


# ==========================================
# 2. å‘å£°ç®¡é“é…ç½®
# ==========================================
def generate_and_play_walle_voice(text):
    normal_wav = "temp_normal.wav"
    walle_wav = "temp_walle.wav"

    if os.path.exists(normal_wav): os.remove(normal_wav)
    if os.path.exists(walle_wav): os.remove(walle_wav)

    try:
        # TTSç”Ÿæˆ
        engine = pyttsx3.init()
        engine.setProperty('rate', 140)
        engine.save_to_file(text, normal_wav)
        engine.runAndWait()

        # SoX DSPå¤„ç†
        sox_cmd = ["sox", normal_wav, walle_wav, "overdrive", "10", "echo", "0.8", "0.8", "5", "0.7", "synth", "sine",
                   "fmod", "30"]
        subprocess.run(sox_cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        # æ’­æ”¾å£°éŸ³
        os.startfile(walle_wav)
    except Exception as e:
        pass  # ä»¿çœŸé˜¶æ®µå¿½ç•¥æ¬¡è¦éŸ³é¢‘æŠ¥é”™


# ==========================================
# 3. ä¸»å¾ªç¯ä¸å¹¶å‘è°ƒåº¦
# ==========================================
def main():
    print("==================================================")
    print("ğŸ¤– WALL-E å…·èº«æ™ºèƒ½å¼•æ“ [å®Œå…¨ä½“ä»¿çœŸç‰ˆ] å·²ä¸Šçº¿")
    print("åŒ…å«ï¼šGemini äº‘ç«¯å¤§è„‘ | DSP å˜å£° | è¿åŠ¨å­¦å¹¶å‘å¼•æ“")
    print("==================================================")

    # åˆå§‹åŒ–è™šæ‹Ÿæœºå™¨äººçš„èº«ä½“
    robot_body = WalleKinematics()

    while True:
        user_input = input("\n[å¼€å‘è€… (è¾“å…¥ 'q' é€€å‡º)]: ")

        if user_input.lower() in ['q', 'quit', 'exit']:
            print("ç³»ç»Ÿå…³é—­ã€‚æ™šå®‰ï¼Œç“¦åˆ©ã€‚")
            break
        if not user_input.strip():
            continue

        try:
            # --- æ€è€ƒé˜¶æ®µ ---
            print("ğŸ§  ç“¦åˆ©æ­£åœ¨æ€è€ƒ...")
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=user_input,
                config=types.GenerateContentConfig(
                    system_instruction=system_instruction,
                    response_mime_type="application/json",
                )
            )

            result = json.loads(response.text)
            text_response = result.get('text', '')
            emotion_tag = result.get('emotion', 'neutral')

            print(f"\n[å†³å®šæƒ…ç»ª]: {emotion_tag.upper()}")
            print(f"[è¾“å‡ºæ–‡æœ¬]: {text_response}\n")

            # --- æ‰§è¡Œé˜¶æ®µ (å¹¶å‘å¤šçº¿ç¨‹) ---
            # 1. å¼€å¯ä¸€ä¸ªç‹¬ç«‹çš„åå°çº¿ç¨‹å»å¤„ç†å¹¶æ’­æ”¾éŸ³é¢‘
            voice_thread = threading.Thread(target=generate_and_play_walle_voice, args=(text_response,))
            voice_thread.start()

            # 2. ä¸»çº¿ç¨‹åŒæ—¶æ‰§è¡Œèˆµæœºçš„ç‰©ç†ç¼“åŠ¨è®¡ç®—
            robot_body.apply_emotion(emotion_tag)
            robot_body.execute_movement(duration=1.5)

            # ç­‰å¾…å£°éŸ³æ’­æ”¾å®Œæ¯•å†è¿›å…¥ä¸‹ä¸€è½®å¯¹è¯
            voice_thread.join()

        except Exception as e:
            print(f"\nâŒ ç³»ç»Ÿå¼‚å¸¸: {e}")


if __name__ == "__main__":
    main()